"""
Main script that loads synthetic data (generated by data_generator.py),
defines local tools, constructs the LlmAgent and InMemoryRunner, and runs a sample analysis.
"""
import asyncio
import json
import os
import time
from pathlib import Path
from typing import List

import pandas as pd


os.environ["GOOGLE_API_KEY"] = ""

# imports for agent
from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.runners import InMemoryRunner
from google.genai import types

# import data generation helpers
import data_generator as dg

# Make defaults
DATA_DIR = Path("data")
BILLING_CSV = DATA_DIR / "synthetic_billing.csv"
METRICS_JSONL = DATA_DIR / "synthetic_metrics.jsonl"
ASSETS_JSON = DATA_DIR / "assets.json"

# Local in-memory caches (loaded soon)
billing_df: pd.DataFrame = pd.DataFrame()
metrics_list: List[dict] = []
assets_list: List[dict] = []

# --- Utility: ensure data exists (load or generate) ---
def load_or_generate_data(generate_if_missing: bool = True):
    """
    Loads data from ./data; if any file is missing and generate_if_missing True,
    generate all files with data_generator.generate_all().
    """
    global billing_df, metrics_list, assets_list

    missing = []
    for path in (BILLING_CSV, METRICS_JSONL, ASSETS_JSON):
        if not path.exists():
            missing.append(path)

    if missing:
        if generate_if_missing:
            print("Missing data files found — generating synthetic data...")
            dg.generate_all(out_dir=str(DATA_DIR), days=365, projects=30)
        else:
            raise FileNotFoundError(f"Missing data files: {missing}")

    # load billing as DataFrame
    billing_df = pd.read_csv(BILLING_CSV, parse_dates=["usage_start_time"])
    # load metrics as list of dicts
    with open(METRICS_JSONL, "r") as f:
        metrics_list = [json.loads(l) for l in f]
    # assets
    with open(ASSETS_JSON, "r") as f:
        assets_list = json.load(f)

    print("Loaded data:")
    print(f" - billing rows: {len(billing_df)}")
    print(f" - metrics lines: {len(metrics_list)}")
    print(f" - assets: {len(assets_list)}")


# --- Local tool functions (to be passed to the agent) ---
def bq_query_cost_by_project(project_id: str, num_days: int):
    """
    Emulate a BQ-style query: return total cost per project in the last num_days.
    """
    cutoff = pd.Timestamp.utcnow() - pd.Timedelta(days=num_days)
    # billing_df is expected to have usage_start_time parsed as datetime
    out_df = billing_df[billing_df["usage_start_time"] >= cutoff.strftime("%Y-%m-%d")]
    out = out_df.groupby("project_id").cost.sum().reset_index().to_dict(orient="records")
    return out


def monitoring_fetch_cpu(instance: str, days: int):
    """
    Return the last `days` metrics for the named instance.
    """
    inst_metrics = [m for m in metrics_list if m["instance"] == instance]
    # return up to last `days` entries
    return inst_metrics[-days:]


def ticket_create(title: str, body: str):
    """
    Emulate ticket creation and return a ticket string/object.
    """
    ticket = {
        "ticket_id": f"TCK-{abs(hash(title)) % 100000}",
        "title": title,
        "body": body,
        "created_at": time.time()
    }


# --- Build the agent and runner ---
def build_cloud_cost_agent():
    retry_config = types.HttpRetryOptions(
        attempts=5,  # Maximum retry attempts
        exp_base=7,  # Delay multiplier
        initial_delay=1,
        http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
    )

    # model choice — keep same as your original sample
    model = Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config)

    cloud_cost_agent = LlmAgent(
        name="cloud_cost_agent",
        model=model,
        instruction=(
            "You are a Cloud Cost Agent.\n"
            "Your job is to analyze cost data, detect spikes, inspect metrics, and provide safe recommendations.\n\n"
        ),
        tools=[
            bq_query_cost_by_project,
            monitoring_fetch_cpu,
            ticket_create
        ]
    )
    print("------------- cloud_cost_agent created -------------")
    return cloud_cost_agent


# We'll create the runner globally after building agent
RUNNER = None


# --- Analysis orchestration ---
def detect_spikes_for_project(project_id: str, days: int = 30, pod: str = "prod"):
    """
    Local detection + assemble prompt for the LLM-based agent.
    Returns the prompt string (so we can inspect before sending) and some local context.
    """
    # ensure datetime column is proper
    global billing_df
    billing_df["usage_start_time"] = pd.to_datetime(billing_df["usage_start_time"])
    if billing_df["usage_start_time"].dt.tz is not None:
        billing_df["usage_start_time"] = billing_df["usage_start_time"].dt.tz_convert(None)

    cutoff = pd.Timestamp.utcnow().replace(tzinfo=None) - pd.Timedelta(days=days)
    proj_df = billing_df[
        (billing_df.project_id == project_id) &
        (billing_df.usage_start_time >= cutoff)
    ].copy()

    if proj_df.empty:
        return None, {"spikes": [], "metrics_sample": [], "explanation": "No billing data for project."}

    mean = proj_df.cost.mean()
    std = proj_df.cost.std() if proj_df.cost.std() > 0 else 1.0
    spikes_df = proj_df[proj_df.cost > mean + 2.5 * std]
    print("Spikes detected: ", spikes_df)

    # fetch sample monitoring metrics
    mon_instance = "vm-prod-1" if pod == "prod" else "vm-dev-1"
    mon_res = monitoring_fetch_cpu(mon_instance, days)

    spike_count = len(spikes_df)
    prompt = (
        f"You are the Cloud Cost Agent (cloud_cost_agent).\n"
        f"Project: {project_id}\n\n"
        f"Recent billing rows (tail):\n{proj_df.tail(8).to_dict(orient='records')}\n\n"
        f"No. of spikes detected:\n{spike_count}\n\n"
        f"Recent CPU metrics for {mon_instance} (sample):\n{mon_res[-8:]}\n\n"
        f"Title:\nCost Spike detected for {project_id}\n\n"
        f"Body: {spikes_df.to_dict(orient='records')}\n\n"
        "Task: Explain the most likely cause of the cost spike in plain English. "
        "Then provide a prioritized list of safe remediation steps (non-destructive first). "
        "Also include one suggested follow-up action that requires human approval. "
        "Create a ticket if there are any spikes, and share all the ticket details."
    )
    meta = {
        "spike_count": spike_count,
        "spikes": spikes_df.to_dict(orient="records"),
        "metrics_sample": mon_res[-8:]
    }
    return prompt, meta


# --- Async runner invocation ---
async def run_analysis_with_agent(project_id: str, days: int = 30, pod: str = "dev"):
    global RUNNER
    if RUNNER is None:
        agent = build_cloud_cost_agent()
        RUNNER = InMemoryRunner(agent=agent)

    prompt, meta = detect_spikes_for_project(project_id=project_id, days=days, pod=pod)
    if prompt is None:
        print("No billing data — nothing to analyze.")
        return meta

    # pass prompt string to runner
    try:
        # run_debug returns detailed output for debugging
        await RUNNER.run_debug(prompt)
        # print("Agent result:")
        # print(res)
        # return {"agent_result": res, "meta": meta}
    except Exception as e:
        print("Error running agent:", repr(e))
        # return {"error": repr(e), "meta": meta}


# --- Entrypoint / main ---
def main():
    # load or generate data automatically if missing
    load_or_generate_data(generate_if_missing=True)

    # run sample analysis asynchronously
    project_to_analyze = "proj-18"
    days = 150
    pod = "dev"

    # asyncio run the async invocation
    asyncio.run(run_analysis_with_agent(project_to_analyze, days=days, pod=pod))


if __name__ == "__main__":
    main()
